---
title: "Dives"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
```

```{r libraries, include=F}
# Load libraries
library(tidyverse)
library(sf)
library(bigrquery)
library(lubridate)
library(hms)


# Load source
source(file.path(here::here(), "src", "common.R"))

# Vessel info
vessel_info <- read_csv(file.path(project_data_path, "processed", "ais_vessel_list.csv"))
```

# Objective

This markdown takes the initial list of possible dive sites (all grid cells where any vessel spent at least 1.5 hours) and gathers a list of dives for each vessel from January 1, 2016 - November 30, 2022. A "dive" is considered any time a vessel is stationary (moved slower than 1 knot) at an identified dive site for at least 1.5 hours. For each dive we retain the following information:  

  - Vessel name  
  - Hours: time spent in that grid cell or dive site  
  - First timestamp: first timestamp (UTC) within the grid cell   
  - Last timestamp: last timestamp (UTC) within the grid cell  
  - Overnight: if the first and last timestamp are on different days  
  - Time of day: early morning (first timestamp before 6am), day (first timestamp between 6am and 6pm), night (first timestamp after 6pm), overnight    
  - Month: month of dive  
  - Year  

We then look at defining "core" dive sites based on the frequency of visits per year. We do this looking at all vessels over all years and classifying the top 25% as "high" frequency, the next 25% as "medium" frequency, and the bottom 50% as "low" frequency. Finally, we match AIS positions to dive sites and add site specific information including nearest island, distance to shore, site category (in mpa, in buffer, outside), MPA name, and MPA type (Marine Reserve, Conservation Area).  

# AIS Positions

```{r sql-ais-positions, include=F, eval=F}
# Keeping only coordinates where vessels moved slower than 1 knot 2016 - November 30, 2022
sql_ais_locations <- "#StandardSQL

SELECT
  ssvid,
  date,
  month,
  year,
  lat_bin,
  lon_bin,
  MIN(timestamp) AS first_timestamp,
  MAX(timestamp) AS last_timestamp,
  SUM(hours) AS total_hours
FROM (
  SELECT
    ssvid,
    date,
    timestamp,
    EXTRACT(month FROM date) AS month,
    EXTRACT(year FROM date) AS year, 
    FLOOR(lat * 1000) / 1000 + 0.0005 AS lat_bin,
    FLOOR(lon * 1000) / 1000 + 0.0005 AS lon_bin,
    hours
  FROM
    `emlab-gcp.boi_dive_project.ci_ais_activity_all_years`
  WHERE speed_knots < 1
  AND EXTRACT(year FROM date) >= 2016
)
GROUP BY ssvid, date, month, year, lat_bin, lon_bin"

# Run and download 
ais_locations <- bq_project_query("emlab-gcp", sql_ais_locations) %>% 
  bq_table_download(n_max = Inf)

# Remove positions from Ranger, Sunfish, and Islander
ais_locations <- ais_locations %>% 
  filter(!ssvid %in% c(368926530, 338350134, 366813530))

# Timestamps are in UTC - convert to Pacific time so we can classify as day or night based on California time 
# Add overnight = yes or no 
# Add time of day: early morning (before 6am), day (6am-6pm), night(after 6pm but not overnight), overnight
am <- as.POSIXct("06:00:00", tz="US/Pacific", format="%H:%M:%S")
pm <- as.POSIXct("18:00:00", tz="US/Pacific", format="%H:%M:%S")
time_am <- as_hms(am)
time_pm <- as_hms(pm)

ais_locations_pacific <- ais_locations %>% 
  mutate(first_timestamp_pacific = lubridate::with_tz(first_timestamp, "US/Pacific"),
         last_timestamp_pacific = lubridate::with_tz(last_timestamp, "US/Pacific")) %>%
  mutate(overnight = ifelse(date(first_timestamp_pacific) == date(last_timestamp_pacific), "no", "yes")) %>% 
  mutate(first_time = as_hms(first_timestamp_pacific),
         last_time = as_hms(last_timestamp_pacific)) %>% 
  mutate(time_of_day = case_when(overnight == 'no' & first_time < time_am ~ "early_morning",
                                 overnight == 'no' & first_time > time_pm ~ "night",
                                 overnight == 'yes' ~ "overnight",
                                 TRUE ~ "day")) %>% 
  dplyr::select(-first_timestamp, -last_timestamp, -first_time, -last_time)

# Save so this doesn't have to be re-run
#write_csv(ais_locations_pacific, file.path(project_data_path, "processed", "ais_stationary_positions_2016_november_2022.csv"))
```

We count dives from AIS positions where vessels are moving slower than 1 knot and remain stationary within an identified "dive site" cell for at least 90 minutes. We first classify AIS dives by dive site id and then we will add the MPA information for each dive site 1) where in/out is classified based on just Marine Reserves and 2) where in/out is classified on Marine Reserves and Conservation Areas.  

# AIS Dives

```{r ais-dives}
ais_locations <- read_csv(file.path(project_data_path, "processed", "ais_stationary_positions_2016_november_2022.csv"))
dive_sites <- read_csv(file.path(project_data_path, "processed", "dive_sites_1hr30min_1vessel_labeled.csv"))

# Ais dives
ais_dives <- ais_locations %>% 
  # At least 1.5 hours in site 
  filter(total_hours >= 1.5) %>% 
  inner_join(dive_sites, by = c("lat_bin", "lon_bin")) #8,747 dives 

# Quick initial check 
check <- ais_dives %>% 
  group_by(ssvid, date) %>% 
  summarize(dives_per_day = n()) %>% # From 1-7 "dives" per day (e.g. different sites where vessel was stationary for at least 1.5 hours)
  ungroup() 

check_overnight <- ais_dives %>% 
  group_by(overnight) %>% 
  count() #84% daytime 

check_tod <- ais_dives %>% 
  group_by(time_of_day) %>% 
  count() #73% during day 6am-6pm start time
```

# "Core" Dive Sites

For the analysis we'll construct a series of subsets of the dive data, including a subset of "core" divesites that are most often used by the dive vessels. We look at aggregated number of dives across all 12 dive vessels in all years 2016-2022. We classify the top 25% of dive sites as "high" frequency, the next 25% as "medium" frequency, and the bottom 50% as "low" frequency.  

```{r define-core-site}
# Count number of dives at each site aggregated 
agg_site_visits <- ais_dives %>% 
  group_by(site_id) %>% 
  summarize(n_dives = n()) %>% 
  ungroup()

site_visits <- agg_site_visits$n_dives

# Identify quantiles for number of visits 
quants <- quantile(site_visits, probs = c(0, 0.25, 0.5, 0.75, 1))
# Bottom 50% of sites have only 1 dive 
# 75% of sites have or 3 less - middle > 1 and <= 3
# Top 25% have 3+

add_frequency <- agg_site_visits %>% 
  mutate(site_frequency = case_when(n_dives == 1 ~ 'low',
                                    n_dives > 1 & n_dives <= 3 ~ 'medium',
                                    n_dives > 3 ~ 'high'))

# Check 
check_frequency <- add_frequency %>% 
  group_by(site_frequency) %>% 
  summarize(n_total = n()) %>% 
  ungroup() %>% 
  mutate(approx_prop = n_total / 2528) # Pretty close: top 20%, next 25%, bottom 55%

# Add frequency classification 
ais_dives_frequency <- ais_dives %>% 
  left_join(add_frequency %>% 
              dplyr::select(site_id, site_frequency), by = "site_id")


## Frequency based on northern sites only 
agg_n_site_visits <- ais_dives %>% 
  filter(island_group == 'Northern') %>% 
  group_by(site_id) %>% 
  summarize(n_dives = n()) %>% 
  ungroup()

n_site_visits <- agg_nsite_visits$n_dives

# Identify quantiles for number of visits 
n_quants <- quantile(n_site_visits, probs = c(0, 0.25, 0.5, 0.75, 1))
# Bottom 50% of sites have only 1 dive 
# 75% of sites have 2 or less - middle = 2 (could still use > 1 and <= 3)
# Top 25% have 2+ (but could still use 3+)

add_frequency_north <- agg_n_site_visits %>% 
  mutate(site_frequency = case_when(n_dives == 1 ~ 'low',
                                    n_dives > 1 & n_dives <=3 ~ 'medium',
                                    n_dives > 3 ~ 'high'))

# Check 
check_frequency_north <- add_frequency_north %>% 
  group_by(site_frequency) %>% 
  summarize(n_total = n()) %>% 
  ungroup() %>% 
  mutate(approx_prop = n_total / 1440) # 18%, 24%, 58%

# Add frequency classification 
ais_n_dives_frequency <- ais_dives %>% 
  filter(island_group == 'Northern') %>% 
  left_join(add_frequency_north %>% 
              dplyr::select(site_id, site_frequency), by = "site_id")
```


# Add Dive Site Information

Lastly, add the relevant MPA information for each dive site  

```{r dive-site-info}
# All dives 
## 500 meter buffer 
reserves_500 <- read_csv(file.path(project_data_path, "processed", "dive_sites_by_mpa_category_reserves_500m.csv"))
joint_500 <- read_csv(file.path(project_data_path, "processed", "dive_sites_by_mpa_category_joint_500m.csv"))

### Reserves
ais_dives_reserves_500 <- ais_dives_frequency %>% 
  left_join(reserves_500 %>% 
              dplyr::select(site_id, site_category, mpa_id, name, mpa_type), by = "site_id")

### Joint
ais_dives_joint_500 <- ais_dives_frequency %>% 
  left_join(joint_500 %>% 
              dplyr::select(site_id, site_category, name, mpa_type), by = "site_id")

### Combine into single master dataset 
all_ais_dives_500 <- ais_dives_reserves_500 %>% 
  mutate(mpa_definition = "Marine Reserve") %>% 
  bind_rows(ais_dives_joint_500 %>% 
              mutate(mpa_id = NA,
                     mpa_definition = "Marine Reserves & Conservation Areas")) %>% 
  left_join(vessel_info %>% 
              dplyr::select(ssvid, shipname), by = "ssvid") %>% 
  dplyr::select(mpa_definition, ssvid, shipname, date, month, year, first_timestamp_pacific, last_timestamp_pacific, overnight, time_of_day,
                site_id, site_category, site_frequency, lat_bin, lon_bin, total_hours, avg_distance_shore_m, nearest_island, island_group, 
                mpa_id, mpa_name = name, mpa_type)


# Northern dives 
## 500 meter buffer 
### Reserves
ais_n_dives_reserves_500 <- ais_n_dives_frequency %>% 
  left_join(reserves_500 %>% 
              dplyr::select(site_id, site_category, mpa_id, name, mpa_type), by = "site_id")

### Joint
ais_n_dives_joint_500 <- ais_n_dives_frequency %>% 
  left_join(joint_500 %>% 
              dplyr::select(site_id, site_category, name, mpa_type), by = "site_id")

### Combine into single master dataset 
n_ais_dives_500 <- ais_n_dives_reserves_500 %>% 
  mutate(mpa_definition = "Marine Reserve") %>% 
  bind_rows(ais_n_dives_joint_500 %>% 
              mutate(mpa_id = NA,
                     mpa_definition = "Marine Reserves & Conservation Areas")) %>% 
  left_join(vessel_info %>% 
              dplyr::select(ssvid, shipname), by = "ssvid") %>% 
  dplyr::select(mpa_definition, ssvid, shipname, date, month, year, first_timestamp_pacific, last_timestamp_pacific, overnight, time_of_day,
                site_id, site_category, site_frequency, lat_bin, lon_bin, total_hours, avg_distance_shore_m, nearest_island, island_group, 
                mpa_id, mpa_name = name, mpa_type)

##### All dives only 
# 1000 meter buffer 
reserves_1000 <- read_csv(file.path(project_data_path, "processed", "dive_sites_by_mpa_category_reserves_1000m.csv"))
joint_1000 <- read_csv(file.path(project_data_path, "processed", "dive_sites_by_mpa_category_joint_1000m.csv"))

## Reserves
ais_dives_reserves_1000 <- ais_dives_frequency %>% 
  left_join(reserves_1000 %>% 
              dplyr::select(site_id, site_category, mpa_id, name, mpa_type), by = "site_id")

## Joint
ais_dives_joint_1000 <- ais_dives_frequency %>% 
  left_join(joint_1000 %>% 
              dplyr::select(site_id, site_category, name, mpa_type), by = "site_id")

## Combine into single master dataset 
all_ais_dives_1000 <- ais_dives_reserves_1000 %>% 
  mutate(mpa_definition = "Marine Reserve") %>% 
  bind_rows(ais_dives_joint_1000 %>% 
              mutate(mpa_id = NA,
                     mpa_definition = "Marine Reserves & Conservation Areas")) %>% 
  left_join(vessel_info %>% 
              dplyr::select(ssvid, shipname), by = "ssvid") %>% 
  dplyr::select(mpa_definition, ssvid, shipname, date, month, year, first_timestamp_pacific, last_timestamp_pacific, overnight, time_of_day,
                site_id, site_category, site_frequency, lat_bin, lon_bin, total_hours, avg_distance_shore_m, nearest_island, island_group, 
                mpa_id, mpa_name = name, mpa_type)

# 1500 meter buffer 
reserves_1500 <- read_csv(file.path(project_data_path, "processed", "dive_sites_by_mpa_category_reserves_1500m.csv"))
joint_1500 <- read_csv(file.path(project_data_path, "processed", "dive_sites_by_mpa_category_joint_1500m.csv"))

## Reserves
ais_dives_reserves_1500 <- ais_dives_frequency %>% 
  left_join(reserves_1500 %>% 
              dplyr::select(site_id, site_category, mpa_id, name, mpa_type), by = "site_id")

## Joint
ais_dives_joint_1500 <- ais_dives_frequency %>% 
  left_join(joint_1500 %>% 
              dplyr::select(site_id, site_category, name, mpa_type), by = "site_id")

## Combine into single master dataset 
all_ais_dives_1500 <- ais_dives_reserves_1500 %>% 
  mutate(mpa_definition = "Marine Reserve") %>% 
  bind_rows(ais_dives_joint_1500 %>% 
              mutate(mpa_id = NA,
                     mpa_definition = "Marine Reserves & Conservation Areas")) %>% 
  left_join(vessel_info %>% 
              dplyr::select(ssvid, shipname), by = "ssvid") %>% 
  dplyr::select(mpa_definition, ssvid, shipname, date, month, year, first_timestamp_pacific, last_timestamp_pacific, overnight, time_of_day,
                site_id, site_category, site_frequency, lat_bin, lon_bin, total_hours, avg_distance_shore_m, nearest_island, island_group, 
                mpa_id, mpa_name = name, mpa_type)

## Save
write_csv(all_ais_dives_500, file.path(project_data_path, "processed", "ais-dives", "all_ais_dives_2016_november_2022_500m.csv"))
write_csv(n_ais_dives_500, file.path(project_data_path, "processed", "ais-dives", "northern_ais_dives_2016_november_2022_500m.csv"))
write_csv(all_ais_dives_1000, file.path(project_data_path, "processed", "ais-dives", "all_ais_dives_2016_november_2022_1000m.csv"))
write_csv(all_ais_dives_1500, file.path(project_data_path, "processed", "ais-dives", "all_ais_dives_2016_november_2022_1500m.csv"))
```


## Subset Scenarios

Ecotourism: dives in the northern Channel Islands, labeled as "day", where the vessel remained stationary in the dive site between 1.5 and 5 hours. This subset gives us 3,537 dives, or ~ 40% of the initial 8,747 AIS dives. We further investigate different subsets of this data for use in the habitat selection model in `src/exploratory-reports/ecotourism_html.Rmd`. 

Around 56% of all AIS identified dives (4,890) are in the Northern Channel Islands. Of these 4,890 dives, 3,537 (or 72%) occurred during the day and have total time at the dive site between 1.5 and 5 hours.  

```{r subset-ecotourism-dives}
north_dives_500 <- read_csv(file.path(project_data_path, "processed", "ais-dives", "northern_ais_dives_2016_november_2022_500m.csv"))

# Subset dives
eco_dives <- north_dives_500 %>% 
  filter(time_of_day == 'day') %>% #3821 dives
  filter(total_hours <= 5) #3537 dives

# Save 
write_csv(eco_dives, file.path(project_data_path, "processed", "ais-dives", "subset_north_max5hr_daytime_500m.csv"))
```

Lobster: dives in the northern Channel Islands during lobster season, with no limitations on time at dive site or time of day. We further explore additional subsets of this data in `src/exploratory-reports/lobster_html.Rmd` for use in the habitat selection model. 

```{r subset-lobster-dives}
all_dives_500 <- read_csv(file.path(project_data_path, "processed", "ais-dives", "all_ais_dives_2016_november_2022_500m.csv"))

## Define lobster season
lobster_season <- data.frame(start_year = c(2016:2022),
                             start_date = c('2016-10-01', '2017-09-30', '2018-09-29', '2019-09-28',
                                            '2020-10-03', '2021-10-02', '2022-10-01'),
                             end_year = c(2016:2022),
                             end_date = c('2016-03-16', '2017-03-15', '2018-03-21', '2019-03-20', 
                                          '2020-03-18', '2021-03-17', '2022-03-16'))

## Subset 
lobster_dives <- all_dives_500 %>% 
  filter(island_group == 'Northern') %>% 
  left_join(lobster_season %>% 
              dplyr::select(start_year, start_date), by = c('year' = 'start_year')) %>% 
  left_join(lobster_season %>% 
              dplyr::select(end_year, end_date), by = c('year' = 'end_year')) %>% 
  # Keep January 1st to end date and start date through December 31
  filter(date >= start_date | date <= end_date)

# Save
write_csv(lobster_dives, file.path(project_data_path, "processed", "ais-dives", "subset_north_lob_season_500m.csv"))
```

## Final Scenarios

Based on the exploratory reports in `src/explotory-reports` we narrow down the dive event data to a single ecotourism scenario and a single lobster scenario which we will use in the habitat selection analysis.  

Ecotourism: Time spent at dive sites is between 1.5 - 5 hours; the first AIS timestamp within the site is between 6 am - 6 pm, excluding any data from October during lobster season. We retain dive events where MPA is defined as both Marine Reserves and Marine Conservation Areas.    

```{r final-ecotourism-dive-events}
eco_dives <- read_csv(file.path(project_data_path, "processed", "ais-dives", "subset_north_max5hr_daytime_500m.csv"))

# Define lobster season
lobster_season <- data.frame(start_year = c(2016:2022),
                             start_date = c('2016-10-01', '2017-09-30', '2018-09-29', '2019-09-28',
                                            '2020-10-03', '2021-10-02', '2022-10-01'),
                             end_year = c(2016:2022),
                             end_date = c('2016-03-16', '2017-03-15', '2018-03-21', '2019-03-20', 
                                          '2020-03-18', '2021-03-17', '2022-03-16'))

# Create other subsets of data from scenario 1
final_eco <- eco_dives %>% 
  left_join(lobster_season %>% 
              dplyr::select(start_year, start_date), by = c('year' = 'start_year')) %>%
  mutate(end_date = paste(year, "10", "31", sep = "-")) %>% 
  # label which days to remove 
  mutate(rm = case_when(year %in% c(2020, 2021, 2022) & date >= start_date & date <= end_date ~ "yes",
                        year %in% c(2016,2017,2018,2019) & month == 10 ~ "yes",
                        TRUE ~ "no")) %>% 
  filter(rm == 'no' & mpa_definition == 'Marine Reserves & Conservation Areas') %>% 
  dplyr::select(-start_date, -end_date, -rm)

# Save
write_csv(final_eco, file.path(project_data_path, "output", "ecotourism_dive_events_mr_mcas.csv"))
```

Lobster: AIS dive event data for lobster season, roughly October to mid-March, where time of day is night or overnight (no maximum site time filters). We retain dive events where MPA is defined as Marine Reserves.      

```{r final-lobster-dive-events}
lobster_dive <- file.path(project_data_path, "processed", "ais-dives", "subset_north_lob_season_500m.csv")

## Subset 
final_lobster <- lobster_dives %>% 
  filter(time_of_day %in% c("night", "overnight") &
           mpa_definition == "Marine Reserve")

# Save
write_csv(final_lobster, file.path(project_data_path, "output", "lobster_dive_events_mr.csv"))
```

