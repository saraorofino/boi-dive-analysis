---
title: "Possible AIS Dive Sites"
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    number_sections: false
    self_contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
```

```{r libraries, include=F}
# Load libraries
library(tidyverse)
library(janitor)
library(stringr)
library(readxl)
library(sf)
library(glue)
library(bigrquery)
library(paletteer)
library(tigris)
library(kableExtra)
library(purrr)


# Load source
source(file.path(here::here(),"common.R"))

# For mapping
ci_shp <- st_read(file.path(project_data_path, "processed", "spatial", "channel_islands.shp"))

## Central CA counties 
ca_counties <- tigris::counties() %>% 
  filter(GEOID %in% c('06083', '06111', '06037', '06059', '06073'))
```


# Objective

Identify possible dive sites in the Channel Islands based on AIS data from dive vessels. 

# AIS Dive Sites

The following approach is used to try and determine dive site locations.  

  - Bin coordinates to a high resolution (0.001 degrees, ~ 111 km)  
  - Identify instances where dive vessels remain stationary in a grid cell for a minimum amount of time, based on survey results this time threshold is 1.5 hours (90 minutes)   
  - Count the number of stationary instances, "dives", in each grid cell   
  - Identify the cells with a number of "dives" above some threshold - these are the dive sites  

This method is a rough adaptation of the GFW anchorage algorithm, more details available [here](https://globalfishingwatch.org/datasets-and-code-anchorages/)  

## Bin Coordinates 

We use AIS data from 2016 - November 30, 2022 gridded to 0.001 x 0.001 degrees and retrieve all positions where vessels are moving slower than 1 knot, which we consider positions where the vessel is stationary. We remove positions from vessels that we've discovered do mostly kayak or other types of non-diving trips: Ranger (368926530), Sunfish (338350134), and Islander (366813530)     

```{r sql-bin-locations, include=F}
# Keeping only coordinates where vessels moved slower than 1 knot 2016-November 30, 2022
sql_bin_locations <- "#StandardSQL

SELECT
  ssvid,
  date,
  lat_bin,
  lon_bin,
  SUM(hours) AS total_hours,
  AVG(distance_from_shore_m) AS avg_distance_shore_m
FROM (
  SELECT
    ssvid,
    date,
    FLOOR(lat * 1000) / 1000 + 0.0005 AS lat_bin,
    FLOOR(lon * 1000) / 1000 + 0.0005 AS lon_bin,
    hours,
    distance_from_shore_m
  FROM
    `emlab-gcp.boi_dive_project.ci_ais_activity_all_years`
  WHERE speed_knots < 1
  AND EXTRACT(year FROM date) >= 2016
)
GROUP BY ssvid, date, lat_bin, lon_bin"

# Run and download 
binned_locations <- bq_project_query("emlab-gcp", sql_bin_locations) %>% 
  bq_table_download(n_max = Inf)

# Remove positions from Ranger, Sunfish, and Islander
binned_locations <- binned_locations %>% 
  filter(!ssvid %in% c(368926530, 338350134, 366813530))
```

## Test Thresholds

The histogram below checks the distribution of the total time spent by a vessel in each grid cell. A vast majority of the positions spend between 0 and 4 hours in a given grid cell although occasionally vessels remain in a grid cell for 12+ hours which may indicate an over night visit. However, since dive vessels may anchor at a dive site overnight that they either ended a night dive or plan to dive in the morning we don't want to exclude these positions. 

```{r time-distribution}
# Check distribution of total time
ggplot(binned_locations, aes(x=total_hours)) +
  geom_histogram(binwidth = 4,
                 boundary = 0,
                 fill = 'slategrey',
                 alpha = 0.95) +
  scale_x_continuous(expand = c(0,0),
                     limits = c(0,40),
                     breaks = seq(0,40,by=4)) + 
  scale_y_continuous(expand = c(0,0)) +
  labs(y = 'Number of AIS positions',
       x = 'Time in grid cell') + 
  theme_bw() # Most positions are 0-4 hours
```
<br>  

The first step is to identify grid cells "visited" by dive vessels, we consider a grid cell "visited" if a dive vessel remains stationary for at least a certain amount of time. Based on survey results from dive operators, most vessels spend about 1.5 hours at a dive site. We'll compare using a cutoff of 1 hour vs. a cutoff of 1.5 hours to see if it makes a difference for capturing dives that might be shorter than the average.   
<br>  

```{r test-thresholds}
## If testing a range
time_thresh <- c(1,1.5)

possible_sites <- NULL

for(i in time_thresh){

  possible_sites <- possible_sites %>%
    bind_rows(binned_locations %>%
                mutate(time_threshold = i) %>%
                mutate(dive = ifelse(total_hours >= time_threshold, 1, 0)))
}

# Number of dives in each grid cell
## Would be place to add a max time cutoff
compare_dives <- possible_sites %>%
  group_by(lat_bin, lon_bin, time_threshold) %>%
  dplyr::summarize(dives = sum(dive))

# Totals by threshold
compare_totals <- compare_dives %>%
  mutate(has_dives = ifelse(dives > 0 , 'yes', 'no')) %>%
  filter(has_dives == 'yes') %>%
  group_by(time_threshold) %>%
  dplyr::summarize(n_cells = n()) %>%
  mutate(diff_cells = c(0, diff(n_cells))) %>% 
  ungroup() %>% 
  mutate(time_threshold = factor(time_threshold))

ggplot(compare_totals) +
  geom_col(aes(x=time_threshold, y=n_cells),
           fill = 'slategrey',
           alpha = 0.95) +
  labs(x='Time Threshold',
       y='Number of unique grid cells "visited" by dive boats') +
  scale_x_discrete(expand = c(0,0),
                   breaks = c(1,1.5),
                     labels = c('1 hr', '1 hr 30 min')) +
  scale_y_continuous(expand = c(0,0)) +
  theme_bw()
```

## Compare Sites 

The next step is to count the number of "visits" or "dives" in each grid cell. We then consider any grid cell with at least `x` dives to be a dive site. We test this threshold of `x` at 1, 2, 3, 4, and 5 dives per year. 

We also test this range of `x` for the 60 minute and 90 minute thresholds. The least restrictive option identifies a "visit" as any time a vessel spends at least 1 hour in a grid cell and 1 dive per year has to occur a grid cell in order for it to be considered as a dive site. The most restrictive option identifies a "visit" as any time a vessel spends at least 1.5 hours in a grid cell and 5 dives per year have to occur in a grid cell in order for it to be considered a dive site. 

The graph below shows the number of grid cells considered as dive sites for each combination of the "visit" time threshold (i.e. 60 or 90 minutes) and the number of dives threshold (i.e. 1 dive or 5 dives).    
<br>  

```{r compare-sites}
# Number of dives to be considered a dive site
site_threshold <- seq(1,5,1)

compare_sites  <- NULL

for(i in site_threshold){
  
  compare_sites <- compare_sites %>% 
    bind_rows(compare_dives %>% 
                mutate(site_threshold = i) %>% 
                mutate(dive_site = ifelse(dives >= site_threshold, 1, 0)))
}

# Removes ones that are never dive sites
compare_sites <- compare_sites %>% 
  group_by(lat_bin, lon_bin) %>% 
  mutate(totals = sum(dive_site)) %>% 
  ungroup() %>% 
  filter(totals > 0) %>% 
  dplyr::select(-totals)

# Dive sites by time threshold 
sites_by_threshold <- compare_sites %>% 
  group_by(time_threshold, site_threshold) %>% 
  summarize(n_sites = sum(dive_site)) %>% 
  ungroup() %>% 
  mutate(site_threshold = factor(site_threshold),
         time_threshold = factor(time_threshold)) 


ggplot(data = sites_by_threshold) + 
  geom_col(aes(x= site_threshold, y = n_sites, fill = time_threshold),
           position = 'dodge') +
  scale_fill_manual(values = paletteer::paletteer_d("nationalparkcolors::ArcticGates", n=2),
                    labels = c('1 hr', '1 hr 30 min')) +
  labs(x="Site threshold (minimum number of 'dives' per year)",
       y="Number of dive sites",
       fill = "Time threshold") + 
  scale_x_discrete(expand = c(0,0),
                   breaks = seq(1,5,1)) + 
  scale_y_continuous(expand = c(0,0)) +
  theme_bw()
```

## Site Maps

The maps below identify what dive sites are added as the time threshold decreases. It first identifies grid cells considered as "dive sites" if the time spent in a grid cell is at least 1.5 hours. It then looks at what new grid cells are added if the time spent in a grid cell decreases to 1 hour. 

There is a different map for each of the three site thresholds (i.e. 1, 2, 3, 4, or 5 dives)  

```{r map-dive-sites}
# Identify the coastal sites that aren't in the CI 
coastal_sites <- compare_sites %>%
  #filter(site_threshold == 1) %>% 
  mutate(coastal_site = case_when(lat_bin > 34.1115 & lon_bin > -120 ~ 'yes',
                                  lat_bin > 34.25 & lon_bin < -120 ~ 'yes',
                                  lat_bin == 33.7235 ~ 'yes',
                                  lat_bin == 33.7245 ~ 'yes',
                                  lat_bin > 33.51 & lon_bin > -119 ~ 'yes',
                                  TRUE ~ 'no'))

# Confirm we have the correct sites to remove 
check_map <- ggplot() + 
    geom_sf(data = ca_counties, fill = NA) + 
    geom_sf(data = ci_shp, fill = NA) + 
    geom_point(data = coastal_sites, aes(x=lon_bin, y=lat_bin, color = coastal_site)) 
    
# Remove the sites that look like they're coastal and not in the CI 
compare_sites_filtered <- compare_sites %>% 
  left_join(coastal_sites) %>% 
  filter(coastal_site != 'yes') %>% 
  # Fix a couple that were missed 
  mutate(coastal_site = ifelse((lon_bin < -119 & lon_bin >= -119.3015) & lat_bin > 34.0385, 'yes', coastal_site)) %>% 
  filter(coastal_site != 'yes') %>% 
  dplyr::select(-coastal_site)
  
  
for(i in site_threshold){
  
  site_cutoff <- compare_sites_filtered %>% 
    filter(site_threshold == i,
           dive_site == 1) %>% 
    mutate(time_threshold = factor(time_threshold))
  
  maxi <- max(sites_by_threshold$n_sites[sites_by_threshold$site_threshold == i])
  mini <- min(sites_by_threshold$n_sites[sites_by_threshold$site_threshold == i])
  
  site_map <- ggplot() + 
    geom_sf(data = ca_counties, fill = NA) + 
    geom_sf(data = ci_shp, fill = NA) + 
    geom_point(data = site_cutoff,
               aes(x=lon_bin, y=lat_bin, color=time_threshold)) + 
    scale_color_manual(values = paletteer::paletteer_d("nationalparkcolors::ArcticGates", n=2),
                       labels = c('1 hr', '1 hr 30 min')) + 
    labs(x="",
         y="",
         title = paste0("Site threshold: ", i, " vessels per year"),
         color = "Time threshold",
         subtitle = paste0("Max dive sites: ", maxi, "; Min dive sites: ", mini)) + 
    theme_bw() + 
    theme(axis.text = element_blank(),
          axis.ticks = element_blank())
  
  print(site_map)
}
```

For now we move forward with the least restrictive set of parameters:  
 - Time threshold: 1.5 hours 
 - Site threshold: 1 vessels   
 
We can always classify sites as most vs. least visited once we look at vessel tracks but we don't want to eliminate sites that might be sites by being too restrictive.  
 
```{r save-dive-sites, include=F}
dive_sites <- compare_sites_filtered %>% 
  filter(time_threshold == 1.5 & site_threshold == 1 & dive_site == 1) %>% 
  dplyr::select(lat_bin, lon_bin) %>% 
  distinct() %>% 
  arrange(lat_bin, lon_bin) %>% 
  mutate(site_id = 1:nrow(.))
```

# Add Dive Site Characteristics 

For each dive site calculate the distance from the nearest shore (m) and assign each to the closest island. 

```{r add-island-distance}
# Get avg distance from shore for each site 
avg_distance <- dive_sites %>% 
  left_join(binned_locations %>% 
              dplyr::select(lat_bin, lon_bin, avg_distance_shore_m) %>% 
              distinct() %>% 
              group_by(lat_bin, lon_bin) %>% 
              summarize(avg_distance_shore_m = mean(avg_distance_shore_m)) %>% 
              ungroup(),
            by = c("lat_bin", "lon_bin")) 

# Assign each dive site to the closest island
sites_sp <- st_as_sf(avg_distance, 
                     coords = c("lon_bin", "lat_bin"),
                     crs = 4269)

ci_shp_nad83 <- ci_shp %>% 
  st_transform(crs = 4269)

closest <- list()
for(i in seq_len(nrow(sites_sp))){
    closest[[i]] <- ci_shp_nad83[which.min(
    st_distance(ci_shp_nad83, sites_sp[i,])),]
}

# Extract poly id 
closest_island <- map_chr(closest, 2)

# Add back in 
dive_sites_island <- avg_distance %>% 
  mutate(nearest_island = closest_island)

# Check on map 
check_islands <- ggplot() + 
  geom_sf(data = ca_counties, fill = NA) + 
  geom_sf(data = ci_shp, fill = NA) + 
  geom_point(data = dive_sites_island,
             aes(x=lon_bin,
                 y=lat_bin,
                 color = nearest_island),
             alpha = 0.7,
             size = 0.2) +
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0)) + 
  labs(x="",
       y="",
       color="Nearest Island") + 
  theme_bw() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank()) # Looks good 
```


# Final Site List

At this stage we only remove sites that are further than 10 km from shore. These sites will be further subset for analysis.  

<br>   

```{r site-harbor-overlap, include=F}
# Unique dive sites 
unique_sites <- dive_sites_island %>% 
  mutate(site_type = 'AIS') #2556 sites

# Remove sites > 10000 meters (10 km)
dive_sites_final <- unique_sites %>% 
  filter(avg_distance_shore_m <= 10000) %>%
  mutate(island_group = ifelse(nearest_island %in% c("San Miguel", "Santa Rosa", "Santa Cruz", "Anacapa"), "Northern", "Southern")) %>% 
  # Make nearest island a factor based on island order
  mutate(nearest_island = factor(nearest_island, levels = c("San Miguel", "Santa Rosa", "Santa Cruz", "Anacapa",
                                                            "Santa Barbara", "San Nicolas", "Catalina", "San Clemente"))) %>% 
  arrange(island_group, nearest_island) %>% 
  # Fix numbering 
  mutate(site_id = 1:nrow(.)) %>% 
  dplyr::select(site_id, lat_bin, lon_bin, avg_distance_shore_m, nearest_island, island_group) #2528 sites

## Check sites in Northern CI only
check_north_ci <- dive_sites_final %>% 
  filter(island_group == "Northern") #1440 sites
```

```{r dive-site-map}
northern_ci <- ci_shp %>% 
  filter(poly_id %in% c("San Miguel", "Santa Rosa", "Santa Cruz", "Anacapa"))

final_site_map <- ggplot() + 
  #geom_sf(data = ca_counties, fill = NA) + 
  geom_sf(data = northern_ci, fill = NA) + 
  geom_point(data = check_north_ci,
             aes(x=lon_bin,
                 y=lat_bin,
                 color = nearest_island),
             alpha = 0.7,
             size = 0.2) +
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0)) + 
  scale_color_manual(values = c('#91D5DEFF', '#2E8289FF', '#B4674EFF', '#EAAE37FF')) +
  labs(x="",
       y="",
       color="") + 
  theme_bw() +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank())

final_site_map
```


```{r save-site-list, include=F, eval=F}
# Save
write_csv(dive_sites_final, file.path(project_data_path, "processed", "dive_sites_1hr30min_1vessel_labeled.csv"))
```


```{r check-sgsb-mpa-overlap, include=F}
# Shps
ci_shp <- st_read(file.path(project_data_path, "processed", "spatial", "channel_islands.shp")) %>% 
  filter(island %in% c("San Miguel", "Santa Rosa", "Santa Cruz", "Anacapa"))
mpa_shp <- st_read(file.path(project_data_path, "processed", "spatial", "north_channel_islands_mpas.shp"))

# List of dive sites from Spotting Giant Sea Bass 
seabass_sites <- read_xlsx(file.path(project_data_path, "raw", "SGSB_encounter_sites_reformatted.xlsx"),
                           sheet = 'Sheet1') %>% 
  clean_names()

# Filter out missing locations
seabass_sites <- seabass_sites %>% 
  filter(!is.na(latitude) | !is.na(longitude))

# Dive sites as points
seabass_sf <- st_as_sf(seabass_sites, coords = c("longitude", "latitude"),
                       crs = 4326)

# Overlap with MPAs
seabass_mpa <- st_intersection(seabass_sf, mpa_shp)

# Classify sites in Channel Islands 
seabass_sites <- seabass_sites %>% 
  mutate(ci_site = case_when(str_detect(site_name, "Anacapa") ~ 'yes',
                             str_detect(site_name, "Catalina") ~ 'yes',
                             str_detect(site_name, "Channel Islands") ~ 'yes',
                             str_detect(site_name, "San Clemente") ~ 'yes',
                             str_detect(site_name, "San Nicolas") ~ 'yes',
                             str_detect(site_name, "Santa Barbara") ~ 'yes',
                             str_detect(site_name, "Santa Cruz") ~ 'yes',
                             TRUE ~ 'no'),
         island = case_when(str_detect(site_name, "Anacapa") ~ 'Anacapa',
                            str_detect(site_name, "Catalina") ~ 'Catalina',
                            str_detect(site_name, "Channel Islands") ~ 'Channel Islands',
                            str_detect(site_name, "San Clemente") ~ 'San Clemente',
                            str_detect(site_name, "San Nicolas") ~ 'San Nicolas',
                            str_detect(site_name, "Santa Barbara") ~ 'Santa Barbara',
                            str_detect(site_name, "Santa Cruz") ~ 'Santa Cruz',
                            TRUE ~ 'NA'))
# Filter for only CI sites
ci_sites <- seabass_sites %>% 
  filter(ci_site == 'yes') %>% 
  mutate(in_mpa = ifelse(site_name %in% seabass_mpa$site_name, "yes", "no"))

ci_sites_sf <- st_as_sf(ci_sites, coords = c("longitude", "latitude"),
                        crs = 4326)


# Map island MPAs, all SGSB sites in CI and sites in MPAs
mpa_types <- mpa_shp %>% 
  mutate(mpa_type = ifelse(str_detect(mpa_type, "Conservation"), "Marine Conservation Area", "Marine Reserve"))

seabass_map <- ggplot() + 
  geom_sf(data = ci_shp, fill = '#C9D2D3', 
          color = '#B4B4B4', size = 1) + 
  geom_sf(data = mpa_types,
          aes(fill=mpa_type), color=NA,
          alpha = 0.7) + 
  geom_sf(data = ci_sites_sf, aes(color=in_mpa),
          size = 1) + 
  scale_fill_manual(values = c('darkcyan', 'firebrick'),
                    guide = guide_legend(order = 1),
                    name = "MPA Type") +
  scale_color_manual(values = c("wheat4", "darkgreen"),
                     labels = c("No", "Yes"),
                     name = "In MPA") + 
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0)) + 
  labs(x="",
       y="") + 
  theme_bw() + 
  theme(legend.margin=margin(0,0,0,0, unit="cm"),
        legend.position = 'bottom',
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank()) + 
  coord_sf(xlim = c(-119.35, -120.61),
           ylim = c(33.8, 34.21))


ggsave(plot = seabass_map, 
       filename = file.path(project_figure_path, "northern_seabass_sites_mpa_overlap.png"))
```

 